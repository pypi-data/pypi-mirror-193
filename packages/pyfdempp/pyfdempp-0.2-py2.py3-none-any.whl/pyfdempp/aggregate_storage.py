import os
import glob

import pyvista as pv
import h5py
from tqdm import tqdm

class aggregate_storage:
    """Aggregator class to store VTK files in a single h5 file for faster access to data.
    """
    def file_group_key(self,vtkfilename):
        """Produces a standard group/key based on VTK file name

        :param vtkfilename: VTK file name to be stored/read
        :type vtkfilename: str path
        :return: Key described using timestep and filename
        :rtype: str
        """
        basename = os.path.basename(vtkfilename)
        timestep = os.path.splitext(basename)[0].split("_")[-1]
        return timestep+"/"+basename

    def _store_file_init(self,f,vtkfilename,compression=None):
        """Protected function to store vtk file data into h5 file

        :param f: H5 file handle with write permissions enabled
        :type f: HDF5 file handle (mode w)
        :param vtkfilename: Path to vtk file
        :type vtkfilename: str path
        """
        groupkey = self.file_group_key(vtkfilename)
        data = pv.read(vtkfilename)
        array_names = data.array_names
        points = data.points
        cells = data.cells
        offsets = data.offset
        celltypes = data.celltypes
        ds = f.create_dataset(groupkey+"/points",points.shape,points.dtype,compression=compression)
        ds[()] = points
        ds = f.create_dataset(groupkey+"/cells",cells.shape,cells.dtype,compression=compression)
        ds[()] = cells
        ds = f.create_dataset(groupkey+"/offsets",offsets.shape,offsets.dtype,compression=compression)
        ds[()] = offsets
        ds = f.create_dataset(groupkey+"/celltypes",celltypes.shape,celltypes.dtype,compression=compression)
        ds[()] = celltypes
        nondataarrays = ["cells","offsets","celltypes",'points']

        for array_name in array_names:
            if not any(x in array_name for x in nondataarrays):
                array = data.get_array(array_name)
                ds = f.create_dataset(groupkey+"/"+array_name,array.shape,array.dtype,compression=compression)
                ds[()] = array

    def store_file(self,vtkfilename):
        """Stores VTK file into HDF5 file

        :param vtkfilename: VTK file name
        :type vtkfilename: str path
        """
        f_w = h5py.File(self.h5filename,"w")
        self._store_file_init(f_w,vtkfilename)
    
    def _check_files_stored(self):
        """Check whether files that are found in __init__ are in HDF5 file already

        :return: Check if the files were properly stored in HDF5 file
        :rtype: bool
        """
        try:
            f = h5py.File(self.h5filename,'r')
        except:
            return False
        timesteps = f.keys()
        files = [os.path.basename(x) for x in self.files]
        
        for ts in timesteps:
            ts_files = f[ts].keys()
            for ts_file in ts_files:
                if ts_file in files:
                    files.remove(ts_file)
                else:
                    return False

        if not files:
            return True
    def __init__(self,file_directory,h5filename=None,overwrite=False,compression=None,verbose=True):
        """Initializes aggregate storage of VTK to HDF5 data system.

        The following steps are performed:
        1. The HDF5 filename is autogenerated if not supplied
        2. The File directory is scanned for *.vtu and *.vtp files
        3. The HDF5 file is checked for completeness if it exists. (Deleted if overwrite=True)
        4. 

        :param file_directory: Folder containing the VTK files
        :type file_directory: str path
        :param h5filename: Name of HDF5 file to be created, defaults to None
        :type h5filename: str path, optional
        :param overwrite: Overwrite any existing HDF5 file, defaults to False
        :type overwrite: bool, optional
        :param verbose: Produce print statements outlining progress, defaults to True
        :type verbose: bool, optional
        """
        # Settle HDF5 filename
        if h5filename is None:
            h5filename = os.path.join(file_directory,"aggregated.h5")
        else:
            if not os.path.isabs(h5filename):
                h5filename = os.path.join(file_directory,h5filename)
        self.h5filename = h5filename
        
        # Scan directory for files
        self.file_directory = file_directory
        self.files = glob.glob(file_directory+"/*.vtu") + glob.glob(file_directory+"/*.vtp")
        
        # Check if HDF5 file matches file structure        
        storage_complete = False
        if os.path.exists(h5filename):
            if overwrite:
                os.remove(h5filename)
            else:
                storage_complete = self._check_files_stored()
        
        if storage_complete:
            if verbose:
                print("Files have already been stored.. Skipping storage process")
        else:
            if verbose:
                print(f"Selected directory {file_directory}... {len(self.files)} files found")
                print(f"Storing data in {h5filename}")
                if compression is not None:
                    print(f"Using {compression} compression")
            f_w = h5py.File(h5filename,"w")
            
            # Iterate through files, storing sequentially
            if verbose:
                iterable = tqdm(self.files)
            else:
                iterable = self.files

            for file_name in iterable:
                if verbose:
                    iterable.set_description(f"Storing {os.path.basename(file_name)}")
                self._store_file_init(f_w,file_name,compression=compression)

    def read_file(self,filename,verbose=False):
        """Extract VTK file from HDF5 file given original filename

        The VTK file is reconstructed from the data arrays stored in the HDF5 file. It will be similar but different from the original.

        :param filename: File name to be extracted (unaltered since HDF5 file creation)
        :type filename: str path
        :param verbose: Print progress statements, defaults to False
        :type verbose: bool, optional
        :return: VTK Unstructured Grid as if read from a *.vtp or *.vtu file
        :rtype: VTK Unstructured Grid
        """
        if verbose:
            print(f"Reading {filename}\n")

        groupkey = self.file_group_key(filename)
        # Not sure if this try guard is needed
        try: 
            # swmr required to allow multiprocessing reads
            f = h5py.File(self.h5filename,'r',swmr=True)
        except:
            raise
        group = f[groupkey]

        data = pv.UnstructuredGrid(group['cells'][()],group['celltypes'][()],group['points'][()])
        # Offsets probably not needed but VTK9 is required. Might need reverse compatibility while VTK9 is established?
        nondataarrays = ["cells","offsets","celltypes",'points']
        npoints = group['points'].shape[0]
        for name in group.keys():
            if not any(x in name for x in nondataarrays):
                array = group[name]
                # Cell and Point array classified on number of points existing
                if array.shape[0] == npoints:
                    data.point_arrays.append(group[name],name)
                else:
                    data.cell_arrays.append(group[name],name)
        return data 

# Test code to be deleted
if __name__ == '__main__':
    # # filename = r"S:\20210623_BD_DIC\20210622_BD_test_DIC_clean_working_4\results\DICe_solution.e"
    source_path = r'X:\20210622_irazu_example\UCS_example'
    filename = r'X:\20210622_irazu_example\UCS_example\UCS_femdem.r2m_basic_2000.vtu'
    # test_model = pv.read(filename)
    # test_model.cell_arrays
    # print(test_model.array_names)
    # print(test_model)
    # # pv.plot(test_model)
    files = glob.glob(source_path+"/*.vtu")
    storage = aggregate_storage(source_path,verbose=True,compression="lzf")
    os.remove(os.path.join(source_path,"aggregated.h5"))
    storage = aggregate_storage(source_path,verbose=True)
    recon_path = os.path.join(source_path,"reconstructed")
    if not os.path.exists(recon_path):
        os.mkdir(recon_path)
    for filename in files:
        reformed_model = storage.read_file(filename)
        savefile = os.path.join(recon_path,os.path.basename(filename))
        # print(f"Saving {savefile}")
        reformed_model.save(savefile)
    # print(reformed_model.array_names)
    # reformed_model.plot(scalars='displacement')

