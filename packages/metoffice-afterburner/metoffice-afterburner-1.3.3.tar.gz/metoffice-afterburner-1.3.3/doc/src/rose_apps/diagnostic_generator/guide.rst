********************
Diagnostic Generator
********************

**Status:** Beta-1 Test Version

**Sample Rose Suite:** `u-bg447`_ (login required)

**Rose App Name:** diag_generator

**App Class Path:** :class:`afterburner.apps.diagnostic_generator.DiagnosticGenerator`

.. contents::
   :depth: 3

Overview
========

The Diagnostic Generator app is a Rose-enabled application for calculating what
are usually referred to as custom or derived model diagnostics from one or more
source diagnostics. The app can be configured to run in parallel with a climate
simulation, or it can be run 'off-line', i.e. as a separate post-processing task.

The app will usually be configured to generate a selection of derived diagnostics
at the end of each model integration step (or some other user-defined cycle point).
However, the number of diagnostics to generate, and the frequency at which they
are calculated, is entirely at the user's discretion.

The source diagnostics used to calculate each target diagnostic are identified
either by STASH code or by CF standard name. Additional diagnostic attributes
(such as LBPROC or LBTIM in the case of UM output) may be required to distinguish
between like-named diagnostics that can occur together in some types of model output.

The source model data can be in any file format recognised by Iris, e.g. UM
fieldsfile, UM PP, or netCDF format. The derived diagnostic data is written out
in netCDF-4 classic format by default, though this can be changed by the user
if desired.

Target diagnostics are generated by passing the prerequisite source diagnostic
data to suitable processor classes (or, more accurately, instances of those
classes). The Afterburner software suite includes a number of processor classes
in the :doc:`/apidoc/afterburner.processors`, but it is possible to utilise
user-written classes that are made available via other packages or modules.
 
The Diagnostic Generator app is configured via a text file conforming to Rose's
extended INI file format. The contents of the app config file are described
in detail under the `Configuring the Application`_ section later on in this guide.

Application Inputs
==================

The main input to the application consists of the model data files that contain
the source diagnostics from which target diagnostics are derived. Although the
current beta version of the Diagnostic Generator app has mostly been tested
using diagnostics generated by the Unified Model, in principle it should work
with any Iris-readable output files from other climate models.

It is assumed that all of the model data files reside in a single directory on
the file system since that is the usual layout utilised by the Unified Model
(when the directory is typically the one pointed to by the $DATAM environment
variable).

The names of the files to read for a given diagnostic are determined according
to a user-defined filename template, as discussed under the `Filename Templates`_
section below.

 
Application Outputs
===================

Derived diagnostics are written to netCDF files, one diagnostic per output file.
The files are saved to the directory defined by the ``[data_writer]output_dir``
app config option (see `Data Writer Options`_). The names of the output files are
determined by a filename template, as described in the next section.

.. _filename-templates:

Filename Templates
==================

The Diagnostic Generator app needs to know the names of the input files from which
to read source diagnostics, and also the names of the output files in which to save
derived target diagnostics. This is achieved through the use of user-defined
filename templates, one covering input files, and one covering output files.

Each filename template is a text string containing a combination of free text
and named tokens (from a controlled list - see table below) enclosed in brace
characters, e.g. ``{runid}``. 

By way of example, the default template for PP input files, as defined in the
sample app config file, looks something like this:

.. code-block:: ini

   [data_reader]
   input_filename_template={runid}{dotstream}*.pp 

Here, the ``{runid}`` and ``{dotstream}`` tokens get replaced at runtime with
the values associated with the model diagnostic currently being processed. The
``runid`` token is fairly self-explanatory. The ``dotstream`` token represents
the stream name with a '.' character inserted at position 1, e.g. 'a.py', 'o.ny'
and so on.

A comparable filename template for netCDF output files might look something
like this:

.. code-block:: ini

   [data_writer]
   output_filename_template={runid}_{stream}_{var_name}_{data_start_date}_{data_end_date}.nc

.. note:: In most cases you'll want the filename template to yield *unique names*
   for the set of stream-plus-diagnostic combinations configured for a given
   run of the application. If not then the possibility exists that the output
   file created for a given diagnostic may overwrite that used for a diagnostic
   generated earlier in the processing sequence.

The standard list of recognised filename tokens is shown in the table below.

=========================== =================
Token                       Substituted Value
=========================== =================
model, model_name           Model name, e.g. 'UM'
suite, suite_id, suite_name Suite name, e.g. 'mi-ab123'
runid                       Run ID, e.g. 'ab123' (automatically derived from the suite name)
realm                       Realm abbreviation, e.g. 'a' for atmos (automatically derived from the stream name)
realization, realization_id Realization (ensemble member) identifier, e.g. 'r1i2p3'
stream, stream_id           Stream name, e.g. 'apy' (automatically updated as each stream is processed)
dotstream                   Stream name with a '.' in position 1, e.g. 'a.py' (automaticaly derived from the stream name)
var_id                      STASH code or CF standard name
lbproc                      Value of the LBPROC PP header item (default: 128)
lbtim                       Value of the LBTIM PP header item (default: 122)
data_start_date             The start date of the output data (see also `Datetime Format`_)
data_end_date               The end date of the output data (see also `Datetime Format`_)
=========================== =================

The above list may be extended with arbitrary user-defined tokens simply by adding
an option with the desired name (and a default value) to the ``[namelist:target_diagnostics(_defaults_)]``
section of the app config file. The new option can, and usually should, be
overridden for individual diagnostics.

By way of illustration, to include a custom token named ``mip_name`` in a filename
template one could modify the app config file as follows:

.. code-block:: ini

   [data_writer]
   # amend template to use the mip_name token
   output_filename_template={runid}_{stream}_{mip_name}_{data_start_date}_{data_end_date}.nc
   ...

   [namelist:target_diagnostics(_defaults_)]
   # set some default value for mip_name
   mip_name=undefined
   ...

   [namelist:target_diagnostics(surface_temp)]
   # set mip_name for this diagnostic
   mip_name=tas
   ...

The following modifiers can be appended to any token to handle case conversion:
 
* ``!l`` - convert the token value to lower case
* ``!u`` - convert the token value to upper case
* ``!t`` - convert the token value to title case

To obtain a *lowercase* version of the model_name attribute, for instance, one
would include the token ``{model_name!l}`` in the template string.

It is possible to configure the filename template so that the output files are
stored within a hierarchy of directories. This is achieved by inserting a '/'
character at the appropriate places in the template. In the following example
the output files would get created within subdirectories named after the runid
and stream.

.. code-block:: ini

   [data_writer]
   output_filename_template={runid}/{stream}/{var_name}_{data_start_date}_{data_end_date}.nc

Note that the '/' character is specific to UNIX-like operating systems. Note also
that any missing subdirectories will be created as and when needed, assuming that
your user account has the appropriate filesystem privileges.

Integration With Climate Suites
===============================

The `Running the Application`_ section towards the end of this guide describes
the actual mechanics of invoking the Diagnostic Generator app. The present section
provides some hints as regards how best to incorporate the app into a Rose/cylc
suite.

Although the Diagnostic Generator app can be run independently within a terminal window,
it is envisaged that invoking it under the control of a Rose/cylc suite will be the
preferred mode of operation.

Lifetime of Model Data Files
----------------------------

An important point to bear in mind is that the Diagnostic Generator processes
diagnostic data which it loads from a subset (typically) of the files output by
the climate model at a given cycle point. The particular subset of data files will
depend upon which output streams have been specified in the app config file.

As a consequence of this behaviour it is crucial that, during the execution of
the processing task, the input data files are *neither modified nor deleted by
any other suite task*. In particular, when working with PP files as the input
source, the postproc app must be configured such that the transform and archive
tasks occur either side of the diagnostic generator task. In terms of a cylc
dependency graph this could be depicted schematically as follows:

.. code-block:: ini

   [scheduling]
      [[dependencies]]
         graph = postproc => diag_generator:finish => pparchive

(Note: The actual postproc tasks might have different names in your suites)

The reasoning here is that we want the PP files to remain in situ on disk until
the diagnostic generator task has completed. Otherwise, if the postproc tasks
were to run back-to-back, some of the PP files would be deleted before the task
had a chance to process them.

There is also an assumption that the postproc tasks for successive cycle points
do not overlap in time (i.e. they execute sequentially). This is important because
otherwise the diagnostic generator task would not know which PP files to load and process
at any given cycle point since files from multiple cycles would co-exist in the
suite share directory. Fortuitously, in most standard climate suites, the postproc
task is configured to execute in this manner (though users should verify this). 

Runtime Performance Considerations
----------------------------------

To avoid repeatedly reading a given model data file multiple times (i.e. for multiple
target diagnostics), the Diagnostic Generator app uses Iris's load functions to read
the data for *all* required diagnostics at the commencement of processing of each
data stream.

Loading data from large UM fieldsfiles or PP files is known to impose a substantial
drain on system resources. Similarly, the task of processing model diagnostics,
especially high-resolution fields on multiple levels, is a compute-intensive operation.
Taken together, this means that incorporating the Diagnostic Generator app into a
climate suite can lead to a significant performance overhead. Attempting to process
a large number of diagnostics might, therefore, lead to exceeding system resource
limits. This will of course depend upon the target runtime platform and the system
load at any given moment. Experimentation may be necessary, therefore, in order to
determine appropriate resource limits.

Handling of Output Files
------------------------

As described in the previous section, the app writes netCDF files containing derived
diagnostics to the user-configured output directory. It is the responsibility of
the user or suite creator to configure any additional processing of the output
files that might be required. This might include, for example, copying or moving
the files to some other disk location, or archiving the files to the MASS data
storage system.

If no such additional processing is defined then the files will simply remain
on disk (at least until they get deleted by some or other housekeeping task).

Configuring the Application
===========================

The Diagnostic Generator app is configured by specifying properties in a text file
based upon Rose's custom INI file format. This so-called 'app config file' may
be created and updated manually using your favourite text editor, or else by
using Rose's graphical editor tool (invoked by typing ``rose config-edit`` or,
if you're really pressed for time, ``rose edit``).

A sample app config file is included as part of the reference Rose suite named
`u-bg447`_. Within that suite the app config file can be found at the path
``app/diag_generator/rose-app.conf``. It contains all of the properties currently
recognised by the Diagnostic Generator app, listed with their default values where
appropriate. Some of the less frequently used properties are hidden (from a Rose
point of view) by placing a '!' character at the front of the property or section
definition.

A brief description of each configuration property is provided below on a section
by section basis.

COMMAND EXECUTION
-----------------

Config file section: ``[command]``

Default Command
~~~~~~~~~~~~~~~

.. code-block:: ini

   default=rose env-cat rose-app-run.conf >rose-app-expanded.conf
          =$AFTERBURNER_HOME_DIR/bin/abrun.sh DiagnosticGenerator -c rose-app-expanded.conf -v

This property defines the command that Rose will invoke in order to run the
Diagnostic Generator application. As shown above, the default command makes use of
the ``rose env-cat`` command to expand any environment variables defined in the
runtime version of the app config file (i.e. ``rose-app-run.conf``). The resulting
file is then passed to Afterburner's ``abrun.sh`` script.

Other than to append additional command-line options (as described below under
`Command-Line Options`_), the default command syntax should not normally need to be
modified.

If you're not using Rose to run the Diagnostic Generator app then this property is
ignored.

RUNTIME ENVIRONMENT
-------------------

Config file section: ``[env]``

The following environment variables may be defined in the app config file or else
under the appropriate section of either the ``rose-suite.conf`` file or the
``suite.rc`` file (assuming, that is, the Diagnostic Generator app is being
executed under the control of a Rose/cylc suite).

Afterburner Home Directory
~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   AFTERBURNER_HOME_DIR=/data/users/afterburner/software/turbofan/current

This environment variable is used to define the pathname of the directory within
which the Afterburner software is installed. If this variable is already set
within your runtime environment - e.g. within one of your shell start-up scripts -
then it's not essential to repeat it here (though it doesn't necessarily hurt to
do so). If you're not sure where the Afterburner software is installed at your
site, please contact your local system administrator.

SciTools Module
~~~~~~~~~~~~~~~

.. code-block:: ini

   SCITOOLS_MODULE=scitools/default-current

This environment variable may be used to specify the name of the SciTools module to
load immediately prior to invocation of the Diagnostic Generator app. If it's not
defined then the default SciTools module gets loaded. To prevent loading of *any*
SciTools module this environment variable can be set to 'none'. This might be
desirable if the calling environment has already loaded the required module.

GENERAL OPTIONS
---------------

Config file section: ``[general]``

Abort On Error
~~~~~~~~~~~~~~

.. code-block:: ini

   abort_on_error=[true | false]

By default, a data processing error will result in the app catching an exception,
reporting (and logging) the associated error message, and skipping to the next
diagnostic, or the next stream, to be processed. Setting the ``abort_on_error``
option to true will cause the Diagnostic Generator app to exit immediately.

.. note:: In the current implementation, being unable to find any model data
   for a given diagnostic is *not* considered an error; rather an informational
   message is emitted and processing skips forward to the next diagnostic. If it's
   desired by users, this behaviour could be modified in future versions of the app.   

Model Name, Suite Name & Ensemble Member
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   model_name=UM
   suite_name=u-ab123
   realization=

The ``model_name`` option identifies the climate model responsible for generating
the source diagnostics. It is used to find an associated model definition (in the
``models`` namelist) and to use as a token within filename templates.

The ``suite_name`` option is used to specify the name of the Rose suite that was
used to run the climate simulation.

For ensemble-based simulations the ``realization`` option should be used to specify
the realization identifier denoting the ensemble member, e.g. 'r1i2p3' (as used for
CMIPn-style experiments).

Stream To Process
~~~~~~~~~~~~~~~~~

.. code-block:: ini

   streams=apm,apy

The ``streams`` option is used to specify the default stream, or list of streams,
for each of which the target diagnostics are to be calculated. This option may be
overridden for a particular target diagnostic if it is only required to generate
that diagnostic for a subset of the default stream list.

Calendar Type
~~~~~~~~~~~~~

.. code-block:: ini

   calendar=360_day

The ``calendar`` option is used to specify the calendar type associated with
*all* of the source diagnostics. At present it is not possible to set the
calendar on a per-diagnostic basis.

Datetime Format
~~~~~~~~~~~~~~~

.. code-block:: ini

   datetime_format=%Y%m%d

The ``datetime_format`` option is used to specify the format of datetime strings
incorporated into the names of output files. At present, the filename tokens that
make use of the datetime format are ``{data_start_date}`` and ``{data_end_date}``.

The permitted format codes are as documented for Python's `datetime.strftime`_
function. The default format is ``%Y%m%d``, which yields, for example, a date
string of the form '19701201' for the date 1st Dec 1970.

DATA READER OPTIONS
-------------------

Config file section: ``[data_reader]``

This section is used to specify a number of options pertaining to how source
diagnostics get read from model data files on disk.

Type of Data Source
~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   source_type=[single_directory | data_cache]

The ``source_type`` option specifies the nature of the data source from which
model data files will be read. At present this can either be a single directory,
meaning that all data files are stored below that one location, or an Afterburner-style
data cache, meaning that data files are stored within a structured hierarchy of
directories based upon runid, stream id, and, where applicable, realization id.

In the case of a model simulation that is writing data files to a single output
directory then it is usual to select the ``single_directory`` option (in which
case the ``[data_cache]`` settings can safely be ignored).

Input Directory
~~~~~~~~~~~~~~~

.. code-block:: ini

   input_dir=$DATAM

The ``input_dir`` option defines the pathname of the directory containing
model data files (in the format specified below). The pathname may contain
environment variables; these are best enclosed within braces so as to avoid
potential ambiguity when the path is expanded.

This option only needs to be defined if the ``source_type`` option (see above)
is set to ``single_directory``. Otherwise, for cache-based data sources, the
``[data_cache]base_dir`` option should be specified.

Input File Format & Filename Templates
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   input_file_format=pp
   input_filename_template={runid}{dotstream}*.pp
   timestamp_filename_template={runid}_{stream}_timestamp

The ``input_file_format`` option defines the format of the input model data.
Currently supported formats include UM PP (the default), UM fieldsfile, and netCDF.

The ``input_filename_template`` option specifies the template by which model data
files are identified when the app is run. The list of brace-delimited tokens
which can be used within a template are described under the `Filename Templates`_
section.

The ``timestamp_filename_template`` option only needs to be defined if the file
selection method (see next entry) is set to 'modification_time'.

Input File Selection Method
~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   file_select_method=[sentinel_files | modification_time]

The ``file_select_method`` indicates to the app how it should identify the set
of data files associated with the current suite cycle point. In the case of the
UM it is usually desirable to choose the sentinel_files option. This causes the
app to look for sentinel files with a ``.arch`` extension (be default) within
the task work directory.

If the modification_time option is selected then the app looks for files that
have a modification time more recent than the previous cycle point. The latest
file time for the current cycle point is stored in a timestamp file, the name of
which is determined by the ``timestamp_filename_template`` option (see previous entry).

In the case of a Rose/cylc suite, timestamp files are created in the suite share
directory. Otherwise they are created in the output directory defined by the
``[data_writer]output_dir`` option.

.. note:: Currently, the file selection method is only honoured when selecting
   input data files from a single directory, and not when a data cache is used.
   This limitation will be addressed in a future release of the app.

DATA CACHE OPTIONS
------------------

Config file section: ``[data_cache]``

Data cache options need to be specified when the ``[data_reader]source_type``
option has been set to ``data_cache``.

.. code-block:: ini

   cache_scheme=StreamSplit
   base_dir=path-to-cache-base-dir
   datastore_id=
   read_only=true

The ``cache_scheme`` option is used to select one of the :doc:`data cache schemes </dev_guide/datacaches>`
recognised by the Afterburner software package. A stream-based option should
be selected if model data files are stored in a directory hierarchy based upon
a runid/stream or runid/ensemble/stream layout. If model data files are stored
within a single directory then it is usually more straightforward to specify
this via the ``[data_reader]input_dir`` option (as described above), and ignore
the data cache settings.

The ``base_dir`` option is used to specify the path to the top-level (root) of
the data cache directory hierarchy.

Since the data cache is currently only used to read data from in-cache files the
``datastore_id`` option can be left blank, while the ``read_only`` option should
normally be left set to true (these options are intended for future use in order
to enable data files to be put into the data cache by the Diagnostic Generator app).

DATA WRITER OPTIONS
-------------------

Config file section: ``[data_writer]``

This section is used to specify a number of options pertaining to how and where
target diagnostics get written to disk.

Type of Data Target
~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   target_type=single_directory

At present output files can only be saved to a single directory (though refer to
the `Filename Templates`_ section for information on defining a filename template
which results in files being saved under a hierarchy of subdirectories below the
target output directory).

Output Directory Path
~~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   output_dir=$DATAM/derived

This option specifies the absolute or relative path to the output directory
where netCDF files of derived diagnostic data will get saved. If a relative path
is given then it will be relative to the current working directory from which
the app is invoked. In the case of a Rose/cylc suite this will usually be the
task work directory.

Output File Format & Filename Templates
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   output_file_format=nc
   output_filename_template={runid}_{stream}_{var_name}_{data_start_date}_{data_end_date}.nc

The ``output_file_format`` option defines the format of the output data files.
Currently the only supported output format is netCDF.

The ``output_filename_template`` option specifies the template by which output
data files are constructed. The list of brace-delimited tokens which can be used
within a template are described under the `Filename Templates`_ section.

NETCDF SAVE OPTIONS
-------------------

Config file section: ``[netcdf_saver]``

NetCDF Format
~~~~~~~~~~~~~

.. code-block:: ini

   netcdf_format=NETCDF4_CLASSIC
   overwrite=false

The ``netcdf_format`` option is used to specify the format or 'flavour' of
netCDF to use for output files. The default of NETCDF4_CLASSIC is chosen because
it enables data compression to be applied (if required; see below). Set this
option to NETCDF4 if you need to take advantage of the features provided by the
netCDF-4 enhanced data model.

File Overwriting & Appending
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   overwrite=false
   append=false

By default, the Diagnostic Generator app will *not* overwrite existing output files.
The ``overwrite`` option may be used to control this behaviour.

If it is required to *append* data to an existing file then the ``append`` option
should be enabled (in which case ``overwrite=true`` is implied). The context
within which the app is being run will likely determine whether or not the append
option is useful. For example, if the app is writing out timestamped files - one
per stream-diagnostic combination per cycle point, say - then the same file will
only be written to once.

Compression Options
~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   zlib=true
   complevel=2

Data compression is enabled by default at the specified compression level. You
may want to experiment with different compression settings. Note, however, that
compression levels above, say, 4 are prone to the law of diminishing returns:
it can take a disproportionate amount of time and CPU resource to achieve a small
amount of extra compression.

Unlimited Dimensions
~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   unlimited_dimensions=time

By default, data variables are written out with *no unlimited dimensions* since
this usually leads to smaller output files. If need be, however, one or more (in
the case of netCDF-4) unlimited dimensions can be specified via the ``unlimited_dimensions``
option. In the example above, the time dimension will be unlimited, i.e. it
becomes a so-called record dimension in netCDF-speak. This can be desirable if
later on you are planning to concatenate files together along the time axis.

Additional NetCDF Options
~~~~~~~~~~~~~~~~~~~~~~~~~

The following options are less frequently needed, but are there if you need them.
Refer to the Iris `netcdf.save`_ function documentation for further details.

.. code-block:: ini

   shuffle=false
   fletcher32=false
   contiguous=false
   least_significant_digit=

PROCESSOR DEFINITIONS
---------------------

Config file section: ``[namelist:processors]``

This section is used to define the processor classes needed to generate the
required target diagnostics. Typically there will be one processor definition
for each target diagnostic, though this is not mandated (some general-purpose
processors can, for example, be used to generate different results from
different source data).

Processor Class Path
~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   [namelist:processors(diurnal_temp)]
   class_path=afterburner.processors.diags.DiurnalTemperatureRange

The ``class_path`` option is used to define the full path to the Python class
that implements the processing logic that generates a target derived diagnostic
from one or more source diagnostics. The Afterburner package includes a number
of such processor classes (see :doc:`/processors`) but it is perfectly acceptable
to specify an alternative, user-developed class so long as the module that contains
it can be found on the module search path at runtime.

Initialisation Arguments
~~~~~~~~~~~~~~~~~~~~~~~~

It is possible to specify the values of any initialisation arguments supported by
a particular diagnostic processor class. This is achieved by prefixing the name
of the desired argument with ``init_``. In the case of the DiurnalTemperatureRange
class, for example, which recognises initialisation arguments named ``diagnostic_id``
and ``meaning_period``, these arguments could be specified as shown below:

.. code-block:: ini

   [namelist:processors(diurnal_temp)]
   class_path=afterburner.processors.diags.DiurnalTemperatureRange
   init_diagnostic_id=m01s03i236
   init_meaning_period=year

The Diagnostic Generator app takes care of converting each argument value to its
native Python data type (plain text strings in the example above).

Which initialisation arguments are supported can be determined by examining the
documentation for the relevant Afterburner processor class (see :doc:`/processors`).

Utilising the Derived Diagnostic Processor Classes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The :mod:`afterburner.processors.diags.derived` module contains general-purpose
classes which can be used to generate derived diagnostics based on a user-defined
formula. At present two such classes are available (click on the class names for
further details):

* :mod:`SimpleDerivedDiagnostic <afterburner.processors.diags.derived.SimpleDerivedDiagnostic>`
* :mod:`MipDerivedDiagnostic <afterburner.processors.diags.derived.MipDerivedDiagnostic>`

Both of these classes expect a ``formula`` argument to be specified when they are
instantiated. The example below illustrates definition of a formula for the 'top
of atmosphere radiation balance' quantity based on UM diagnostics as inputs (the
formula could equally be expressed in terms of, say, CF standard names if the
input data sources possess those names in the metadata attached to the data).

This example also includes a target diagnostic which references the specified
processor definition. It assumes that source diagnostics have been defined for
the three identifiers specified against the ``sources`` option (see next section
for more information).

.. code-block:: ini

   [namelist:processors(toa_radiation_balance)]
   class_path=afterburner.processors.diags.derived.SimpleDerivedDiagnostic
   init_formula=m01s01i207 - m01s01i208 - m01s03i332

   [namelist:target_diagnostics(toa_rad_bal)]
   processor=toa_radiation_balance
   sources=sw_flux_down,sw_flux_up,lw_flux_up
   standard_name=toa_net_downward_radiative_flux
   long_name=TOA Radiation Balance
   var_name=toa_rad_bal

The ``MipDerivedDiagnostic`` class, which supports the use of *selected* STASH
constraints within the formula expression, can be used in much the same way as
that shown above.

.. hint:: A dedicated :class:`diagnostic processor class <afterburner.processors.diags.atmos.toa_radiation_balance.ToaRadiationBalance>`
   exists for generating the TOA radiation balance diagnostic from a list of
   Iris cubes.

SOURCE DIAGNOSTIC DEFINITIONS
-----------------------------

Config file section: ``[namelist:source_diagnostics]``

This section is used to define the various source diagnostics needed to generate
the required target diagnostics. Any given source diagnostic potentially can be
used to generate multiple target diagnostics. Default settings that apply to all
source diagnostics can conveniently be defined once under the 'virtual' diagnostic
named ``_defaults_``.

Enabling/Disabling Diagnostics
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   [namelist:source_diagnostics(tas)]
   enabled=true
   ...

Ordinarily each diagnostic is enabled, meaning that it will get detected and
processed by the Diagnostic Generator app. Sometimes, however, it can be useful
to temporarily disable a diagnostic without having to actually delete it from
the app config file. The ``enabled`` option allows you to conveniently switch
diagnostics on and off.

Diagnostic Variable Identifier
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   [namelist:source_diagnostics(tas)]
   # defined by STASH code
   var_id=m01s00i024
   # defined by CF standard name
   var_id=surface_temperature

The ``var_id`` option is used to identify the source model diagnostic. It should
either be a STASH code or a CF standard name, as illustrated in the example above.
For processing UM model diagnostics it will usually be convenient to specify a
STASH code. For other climate models, notably those producing netCDF output files,
a standard name will normally be required.

Start & End Dates
~~~~~~~~~~~~~~~~~

When the app is configured to load model data from files output (by a climate
simulation) to a single directory, then the app can determine which files to load
for the current cycle point, either by examining the file modification time or by
looking for the presence of sentinel files. This will normally be the preferred
mode of operation.

If, however, the model files are stored within an :doc:`Afterburner-style data cache </dev_guide/datacaches>`
then the app needs to be notified of the time period for which data should be loaded
for the current cycle point. This can be achieved by updating the diagnostic's
``start_date`` and ``end_date`` properties at each cycle point using environment
variables -- START_DATE and END_DATE are used in the example below, but you can use
alternative names if you like:

.. code-block:: ini

   [namelist:source_diagnostics(tas)]
   ...
   start_date=$START_DATE
   end_date=$END_DATE

These environment variables should be updated in the ``suite.rc`` file at each
invocation of the cylc task that runs the Diagnostic Generator app. The task
definition shown below uses the ``cylc cyclepoint`` command to set the START_DATE
and END_DATE variables (for successive one-month time periods in this case) within
the ``pre-script`` declaration:

.. code-block:: ini

    [[diag_generator]]
        pre-script = """
            export START_DATE=$(cylc cyclepoint --template=CCYY-MM-DD)
            export END_DATE=$(cylc cyclepoint --offset=P1M --template=CCYY-MM-DD)
            """
        ...

If you use this approach you'll want to modify the ``--template`` and ``--offset``
parameters to suit your particular diagnostic processing needs.

LBPROC & LBTIM Attributes
~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   [namelist:source_diagnostics(tas)]
   ...
   lbproc=128
   lbtim=122
   ...

These two options are used to disambiguate UM diagnostics which share the same
STASH code and which can end up being serialised in the same output file. A common
use is to set the ``lbtim`` option so as to correctly select a diagnostic at a
particular sampling frequency, e.g. 3h, 6h, or 24h.

Reinitialisation Period
~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   [namelist:source_diagnostics(tas)]
   ...
   reinit=30

If daily or instantaneous model data (e.g. from UM streams apa - apk) is being
loaded from files maintained within an Afterburner-style data cache, then it will
usually be necessary to specify the stream reinitialisation period (in days) via
the ``reinit`` option.

In the case of standard climate mean streams (apm, apy, etc) the app is able to
guess the reinitialisation period, though it is possible to override the setting
by specifying a negative value, e.g. -90 would enforce a 90-day reinitialisation
period regardless of stream name.


TARGET DIAGNOSTIC DEFINITIONS
-----------------------------

Config file section: ``[namelist:target_diagnostics]``

This section is used to specify the desired target diagnostics to be generated
by the Diagnostic Generator app.

Enabling/Disabling Diagnostics
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   [namelist:target_diagnostics(diurnal_temp)]
   enabled=true
   ...

Ordinarily each target diagnostic is enabled, meaning that it will get generated
by the Diagnostic Generator app. Sometimes, however, it can be useful to
temporarily disable a diagnostic without having to actually delete it from
the app config file. The ``enabled`` option allows you to conveniently switch
target diagnostics on and off.

Standard Name, Long Name & Variable Name
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   [namelist:target_diagnostics(precip)]
   ...
   standard_name=precipitation_flux
   long_name=Precipitation Flux
   var_name=precip
   ...

These three options can be used to assign correspondingly named metadata
attributes to the generated target diagnostic. This means the in-memory Iris cube
during processing, or the associated netCDF variable after the diagnostic has been
serialised to a netCDF file. None of these options is mandatory though it is
customary -- and helpful -- to specify at least one.

The ``standard_name`` and ``long_name`` options are equivalent to the attributes
of the same name defined in the CF metadata conventions. The ``var_name`` option
may be used to define the name of the output netCDF variable.

Processor ID
~~~~~~~~~~~~

.. code-block:: ini

   [namelist:target_diagnostics(diurnal_temp)]
   ...
   processor=diurnal_temp_range
   ...

The ``processor`` option specifies the namelist ID of the processor that will be
used to generate the target diagnostic. The ID must be the name of one of the
processor definitions configured within the ``processors`` namelist, as described
above under the `PROCESSOR DEFINITIONS`_ section.

Source Diagnostic IDs
~~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   [namelist:target_diagnostics(diurnal_temp)]
   ...
   sources=tas_max,tas_min
   ...

The ``sources`` option specifies the namelist IDs of the source diagnostics from
which the current target diagnostic -- diurnal_temp in the above example -- will
be generated. Each ID in the list must be the name of one of the source diagnostics
configured within the ``source_diagnostics`` namelist, as described above under the
`SOURCE DIAGNOSTIC DEFINITIONS`_ section.

.. warning:: If the processor class that will be used to calculate a target diagnostic
   expects source diagnostics to be handed to it (as Iris cubes at runtime)
   in a particular order then that order should be honoured in the sequence
   of namelist IDs assigned to the ``sources`` option.

CLIMATE MODEL OPTIONS
---------------------

Config file section: ``[namelist:models]``

The ``models`` namelist is used to configure options that are specific to particular
climate models. At present this capability is limited to a couple of options pertinent
to the Unified Model, as described below.

Cylc Task Name
~~~~~~~~~~~~~~

.. code-block:: ini

   [namelist:models(um)]
   cylc_task_name=atmos_main
   ...

The ``cylc_task_name`` option is used to specify the name of the main task in the
Rose/cylc suite that is responsible for running a particular model code (the UM
in this example). The task name is used to obtain various task-related properties,
such as its work directory.

Sentinel File Extension
~~~~~~~~~~~~~~~~~~~~~~~

.. code-block:: ini

   [namelist:models(um)]
   sentinel_file_ext=.arch
   ...

If the numerical model makes use of sentinel files to flag a subset of model
output files for some purpose, then the extension used for the sentinel files
should be defined here. Currently, the main practical application of this option
is to identify the sentinel files created by the UM postproc app as part of the
PP file transform and archive operations.

Setting this option to the empty string (or deleting it entirely) will disable
any related functionality in the Diagnostic Generator app.  

Running the Application
=======================

The Diagnostic Generator app can be run either manually at the shell command
line or automatically under the control of a Rose suite. Both methods are described
in general terms in the :doc:`/invoking` chapter. The guidance in that chapter is
largely applicable to the current context. Some additional app-specific guidance is
included below.

Manual Invocation
-----------------

To run the app manually from the command line, type the following:

.. code-block:: bash

    % export AFTERBURNER_HOME_DIR=<path-to-afterburner-home-dir>
    % $AFTERBURNER_HOME_DIR/bin/abrun.sh DiagnosticGenerator -c <config-file> [options]

An app config file, as described in the previous section, must be specified via
the ``-c`` (or ``--config-file``) option. Additional command-line options are
described below; often it is desirable to turn on the ``-v`` (or ``--verbose``)
option in order to see progress messages.

The initial ``export`` command above is not needed if the AFTERBURNER_HOME_DIR
shell variable is already defined in, for example, one of your shell start-up
scripts. Likewise, if the directory ``$AFTERBURNER_HOME_DIR/bin`` is included in
your command search path, then the second command can be shortened to plain ``abrun.sh``.

If you have checked out (or exported) a working copy of the `Afterburner code base
<https://code.metoffice.gov.uk/trac/afterburner/browser/turbofan/trunk>`_ then you
can, if preferred, set the AFTERBURNER_HOME_DIR variable to point to the directory
containing that working copy.

Invoking the Diagnostic Generator app manually will of course only run it once.
Typically, however, you'll want to run the app at regular cycle points during
the execution of a Rose/cylc suite. This approach is described in the next section.

Invocation from a Rose/Cylc Suite
---------------------------------

Firstly, create a copy of the `u-bg447`_ sample Rose suite (login required).

Next, modify the app config file for the Diagnostic Generator application (i.e.
the file ``app/diag_generator/rose-app.conf``), and also the ``suite.rc`` file,
to suit your particular data source locations and processing requirements.

At this point you can either run the suite in stand-alone mode, or you can copy
the ``app`` directory over to an existing Rose suite and run (or restart) it.
In the latter case it will be necessary to modify the suite's dependency graph
(in the ``suite.rc`` file) so that the ``diag_generator`` task is invoked at
the desired cycle points. Please consult the relevant Rose and cylc documentation
-- or a knowledgeable colleague! -- for further guidance on how to do this.

.. note:: When the Diagnostic Generator app is executed as part of a Rose/cylc suite,
   any output messages will normally be directed to Rose's standard log files
   (which can be viewed by running the Rose command ``rose suite-log``).

Command-Line Options
--------------------

Command-line options can be viewed by invoking the app with the ``-h`` (or ``--help``)
option, as shown below:

.. code-block:: bash

    % abrun.sh --help
    Usage: abrun.sh <app_name> [options] [arguments]

    % abrun.sh DiagnosticGenerator --help
    usage: DiagnosticGenerator [-h] [-V] [-D | -q | -v] [-c CONFIG_FILE]
                               [--abort-on-error]
    
    DiagnosticGenerator: generates derived model diagnostics
    
    optional arguments:
      -h, --help            show this help message and exit
      -V, --version         Show Afterburner version number and exit
      -D, --debug           Enable debug message mode
      -q, --quiet           Enable quiet message mode
      -v, --verbose         Enable verbose message mode
      -c CONFIG_FILE, --config-file CONFIG_FILE
                            Pathname of the app configuration file
      --abort-on-error      Abort processing if an error is encountered

These options are fairly self-explanatory. Note, however, that the -D, -q and -v
options are mutually exclusive.


.. The links below are referenced elsewhere in this document.

.. _u-bg447: https://code.metoffice.gov.uk/trac/roses-u/browser/b/g/4/4/7/trunk

.. _netcdf.save: https://scitools.org.uk/iris/docs/latest/iris/iris/fileformats/netcdf.html#iris.fileformats.netcdf.save

.. _datetime.strftime: https://docs.python.org/2/library/datetime.html#strftime-and-strptime-behavior
