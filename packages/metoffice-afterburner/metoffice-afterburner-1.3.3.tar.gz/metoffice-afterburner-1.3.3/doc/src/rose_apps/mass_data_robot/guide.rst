***************
MASS Data Robot
***************

**Status:** Beta-2 Test Version

**Sample Rose Suite:** `u-an165`_ (login required)

**Rose App Name:** mass_data_robot

**App Class Path:** :class:`afterburner.apps.mass_data_robot.MassDataRobot`

.. contents::

Overview
========

The MASS Data Robot application (MDR app, for short) provides the capability to
configure and execute multiple data retrieval requests against the MASS data archive.
In its present form the MDR app is primarily designed to retrieve climate model
data from the MASS data classes named ``crum`` and ``ens``.

Two main use-cases are envisaged for the MASS Data Robot application:

1. To enable end-users to run multiple MASS data retrieval operations in batch
   mode, without having to repeatedly write and test their own code or scripts
   (or type and launch numerous MOOSE commands).
2. To provide stand-alone machinery which can be integrated into Rose-based
   applications (including those developed as part of Afterburner) in order to
   retrieve the climate model datasets needed as input to those applications.

The fundamental configuration entity that drives the MDR application is the
*composite data request*, this being a request to retrieve one or more variables
/diagnostics, from one or more data collections, from one or more data
sets, and from a *single* MASS data class.

In the case of an ensemble of model runs, the composite request will also define
one or more ensemble member names (also referred to as *realization identifiers*
within this guide).

The MDR app expands composite data requests into one or more discrete data requests
which are suitable for handing off to the MOOSE command-line interface. For example,
the following fictional composite data request, if defined within an app config
file, would result in 4 discrete MOOSE data requests (i.e. retrieve PP files for
all available time periods from 2 data collections from each of 2 data sets)::

    [namelist:requests(1)]
    data_class=crum
    data_sets=mi-ab123,mi-cd234
    data_collections=apy.pp,aps.pp
    variables=*

Additional constraints -- such as a date range -- can be defined in order to
retrieve specific subsets of data collections. These options, and more, are
described in detail under the `Configuring the Application`_ section below.
A number of sample data request definitions can also be found under the
`Example Data Requests`_ section towards the end of this document.

.. note:: Composite data requests must be *internally consistent*, by which is
   meant that any nominated model variables must occur in each specified data
   collection, which in turn must be present in each specified data set. An error
   will be triggered if this hierarchical containment rule is not met.

Task Scripts and Query Files
----------------------------

Each discrete data request is used to auto-generate a shell script which contains
the single MOOSE command (i.e. get, select or filter) that is needed to fetch the
data described by the request. Each shell script contains a few other setup
commands, e.g. to create any required destination directories.

These task or job scripts are stored in a temporary directory below the working
directory from which the MDR application is launched. By default this temporary
directory is named ``mdr_scripts``, though it is possible to specify a different
name in the app config file.

If a particular data request requires the use of a *query file* (for PP data) or
a *filter file* (for netCDF data), then the requisite file is auto-generated and
stored in a temporary directory named ``mdr_query_files`` by default. As before,
a different name can be specified in the app config file.

Task script files and query files (if used) are named using the same data request
identifier, e.g. ``req001_script.sh`` and ``req001_query.txt`` for the first
data request, ``req002_script.sh`` and ``req002_query.txt`` for the second, and
so on. This makes it easy to see which query file matches a given task script.

By default, task script files and query/filter files are deleted at the end of
processing. This teardown step can be skipped if desired; something you may wish
to do if you need to examine the file contents, or perhaps run the task scripts
manually.

Text messages generated by task scripts are output to log files named
``req001.log``, ``req002.log``, and so on. Log files are saved, by default, in
the subdirectory ``mdr_logs`` of the working directory. Successive invocations
of the MDR app in the same working directory will overwrite the log files.

Destination Directories and Data Caches
---------------------------------------

MOOSE data retrieval commands such as ``moo get`` place all retrieved data files
into a single destination directory. Consequently, a mechanism is needed to
control how files retrieved by multiple MOOSE command invocations are stored, in
a reliable and consistent manner, within appropriate target directories.

The approach taken by the MDR app is to make use of Afterburner's data cache
management instrumentation, which is described in detail in the :doc:`/dev_guide/datacaches`
section of the Afterburner documentation. Briefly, however, an Afterburner data
cache is a named scheme, plus associated code, for managing climate model data
files within a predictable directory hierarchy on disk.

A number of data cache schemes have been implemented that mirror popular ways
in which users store and organise model data files on disk. For example, the
"StreamSplit" data caching scheme organises model data files based upon the
familiar hierarchy of directories named according to the principal elements of
a climate model simulation; namely the suite/run identifier and the stream
identifier.

An example set of annual-mean and monthly-mean atmosphere and ocean model files
would be laid out as follows if the StreamSplit data caching scheme was selected::

  mi-ab123/
    apy/
      ab123a.py1970.pp
      ab123a.py1971.pp
      ...
    apm/
      ab123a.pm1970dec.pp
      ab123a.pm1971jan.pp
      ...
    ony/
      ab123_1y_19691201_19701130_grid_T.nc
      ab123_1y_19701201_19711130_grid_T.nc
      ...
    onm/
      ab123_1m_19700101_19700130_grid_T.nc
      ab123_1m_19700201_19700230_grid_T.nc
      ...

As can be seen from the above example, the StreamSplit layout closely mirrors
the layout of files in the MASS data archive itself. The files have the same name,
size and content, i.e. all variables/diagnostics for a given time period are
present in each file.

Another cache scheme which is likely to find widespread applicability is the
"VarSplit" scheme. With this scheme an additional level of subdirectories is used
to separate out data pertaining to each requested variable/diagnostic. Building
on the previous example, the directory and file layout for two annual-mean
atmosphere model diagnostics would appear as follows::

  mi-ab123/
    apy/
      m01s00i024/
        ab123a.py1970.pp     # files only contain fields
        ab123a.py1971.pp     # for STASH code 1,0,24
        ...
      m01s03i236/
        ab123a.py1970.pp     # files only contain fields
        ab123a.py1971.pp     # for STASH code 1,3,236
        ...

Other model streams (apm, ony, onm, iny, inm, etc.) receive similar treatment.

The key difference with the VarSplit scheme is that the cached files only contain
data for the nominated variable/diagnostic -- m01s00i024 or m01s03i236 in the
example above. This makes individual data files significanty smaller and therefore
much quicker to read (within Iris, for instance) than whole-stream files. Moreover,
there is no need to retrieve and store unwanted variables/diagnostics, as happens
with the StreamSplit scheme.

.. note:: The current version of the MASS Data Robot app does not support the
   automatic expansion of an all-variables declaration (``variables=*`` in the
   app config file) to a full set of corresponding files in a VarSplit-based data
   cache. This limitation may be addressed in a future version of the app. Users
   may simulate this functionality by nominating each and every variable; this,
   however, is likely to be impractical -- and undesirable -- in most situations.

The two ensemble-based cache schemes -- "EnsembleStreamSplit" and "EnsembleVarSplit"
-- are similar to their non-ensemble cousins introduced above, the main difference
being that an extra realization subdirectory is inserted between the suite and
stream subdirectories, e.g. the ``r1i1p1`` part of ``mi-ab123/r1i1p1/apy/...``.

Each of the aforementioned Afterburner data cache schemes is described in more
detail in the :mod:`afterburner.io.datacaches` part of the :doc:`API reference
documentation </apiref>`.

Within the context of the MDR app, any number of data cache definitions may be
specified in the app config file (as described later on this guide). Also, it is
often desirable to have the top-level cache directories (one per cache scheme)
co-located on a scratch disk. Adopting this strategy, one might set up the
following directory hierarchy::

  $SCRATCH/
    data_caches/
      ens_stream_split/
        ...
      ens_var_split/
        ...
      stream_split/
        ...
      var_split/
        ...

Note that Afterburner's data caching code automatically creates any missing
cache directories. Hence it isn't essential to pre-create such a hierarchy.

Execution Mode
--------------

The MDR app can be configured to execute multiple MASS data retrieval commands
in one of two modes: parallel or serial. Parallel task execution is the default
mode since it naturally makes more efficient use of the multiple CPUs/cores that
are typically available on today's hardware platforms. However, running in serial
mode can be useful when you are trying to troubleshoot problems.

Parallel execution mode is currently implemented using Python's `multiprocessing`_
module. It is hoped that a future version of the application will include the
option to apply parallelisation using `cylc's <http://cylc.github.io/cylc/>`_
task scheduling features.

Usage Guide
===========

Configuring the Application
---------------------------

The MASS Data Robot application is configured using an app config file, the
structure of which must conform to Rose's extended INI format (although it is
not obligatory to run the MDR app under the control of a Rose suite). The app
config file contains 4 main sections: ``[general]``, ``[moose]``, ``[data_caches]``,
and ``[requests]``.

The first two sections permit the setting of general application options and
of MOOSE-specific options. The last two sections are used to specify data
cache definitions and composite MASS data requests -- both of these sections are
maintained as namelists.

Command Execution (section: command)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

default
    This property defines the default command that Rose will invoke in order to
    run the MASS Data Robot app. Other than to append additional command-line
    options (as described below under `Command-Line Options`_), the default
    command syntax should not normally need to be modified.

Runtime Environment (section: env)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

AFTERBURNER_HOME_DIR
    This environment variable is used to define the pathname of the directory
    within which the Afterburner software is installed. If this variable is
    already set within your run-time environment -- e.g. within one of your shell
    start-up scripts -- then it does not need to be repeated here (though it
    doesn't hurt to do so). If you're not sure where the Afterburner software is
    installed on your system, please contact your local system administrator.

MAX_MOOSE_DATA_REQUESTS
    This optional environment variable specifies the maximum number of discrete MOOSE
    data requests that the MDR app will permit to be created from the composite
    data requests defined in the app config file. If this limit is exceeded then
    the application exits with an appropriate error message. The limit, which is
    100 by default, is enforced so as to avoid saturating the MASS data archive
    with an excessive number of data requests.

SCITOOLS_MODULE
    By default the wrapper script that invokes the MDR app will try to load a
    Python3-based version of the Met Office's Scientific Software Stack (which
    includes packages such as iris, cartopy and matplotlib).

    You can request that a specific SciTools module be loaded by assigning the
    desired module name to this environment variable, e.g.:

    .. code-block:: ini

       [env]
       SCITOOLS_MODULE=scitools/experimental-current

    If you prefer to set up the SciTools module explicitly in the calling
    environment -- e.g. by invoking the ``module load`` command *prior* to running
    the app -- then you should set ``SCITOOLS_MODULE=none``. This will prevent
    the wrapper script from trying to load a default SciTools module.

    .. note:: If you are running the app on a platform that doesn't support SciTools
       as a loadable module, then the wrapper script may emit a warning message to
       this effect. This message can be suppressed (if desired) by setting the
       variable to 'none' as shown in the previous paragraph.

General Options (section name: general)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The figure below illustrates the General Options panel, as displayed by Rose's
config editor tool.

.. image:: images/general_options.png

Parallel Processing Mode (option name: parallel_mode)
    Specifies the parallel processing mode. Currently the only supported mode
    is to use Python's `multiprocessing`_ module (support for task parallelisation
    using the cylc scheduler is being investigated). Alternatively, parallel processing
    can be disabled by selecting the None option, in which case data requests are
    executed in series. This can be useful for troubleshooting run-time issues.
    The ``--pmode`` command-line option may be used to override this property for
    a particular invocation of the MDR app. This is mainly useful when you want
    to run in serial mode (``--pmode=none``) for the purposes of a dry-run of the
    MDR app.

Maximum Number of Concurrent Tasks (option name: max_active_tasks)
    In parallel processing mode, defines the maximum number of concurrent tasks
    (processes). Where appropriate, the specified value should normally match --
    or at least not exceed -- an equivalent option or property defined in a related
    resource configuration file (e.g. the SLURM ``ntasks`` directive if used in
    a cylc suite definition file).

Script Directory (option name: script_dir)
    Specifies the temporary directory within which to store the task scripts
    which encapsulate MOOSE data retrieval commands. By default the directory is
    named ``mdr_scripts``. This directory and its contents are normally deleted
    at the conclusion of processing (cf. the Run Teardown Tasks option below).

Query File Directory (option name: query_file_dir)
    Specifies the temporary directory within which to store any MOOSE query files
    which are needed to run MOOSE data retrieval commands. By default the directory
    is named ``mdr_query_files``. This directory and its contents are normally
    deleted at the conclusion of processing (cf. the Run Teardown Tasks option below).

Log File Directory (option name: log_dir)
    Specifies the directory within which to store any log files generated by the
    task scripts. The log files are named ``req001.log``, ``req002.log``, and so
    on. If this option is undefined then the log file directory defaults to
    ``mdr_logs``. If it is set to the empty string then log messages are sent to
    /dev/null, i.e. messaging is disabled. It's also possible to set this option
    to /dev/stdout or /dev/stderr, which will have their usual effect.

Run Teardown Tasks (option name: run_teardown)
    Indicates whether or not to run teardown tasks as the final processing step.
    This is enabled by default and currently involves deleting the temporary
    directories described above. The ``--no-teardown`` command-line option may be
    used to override this property for a particular invocation of the MDR app.
    This can be useful when you want to quickly review, say, the contents of the
    task scripts without having to edit then reset this option in the app config
    file.

Abort On Error (option name: abort_on_error)
    Indicates whether or not to abort all further processing if an error is
    encountered executing a particular MOOSE data request. By default, any errors
    are reported in the log files, and processing continues onto subsequent data
    requests. Note that in parallel processing mode any currently running threads
    will normally run to completion; only queued tasks will be aborted. If an
    MDR application run is aborted then it passes a non-zero return code (2) to
    the calling program. Thus, if you are invoking the MDR app from a Rose suite,
    it may be desirable to include an on-failure trigger in your dependency graph.

MOOSE Options (section name: moose)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The figure below illustrates the MOOSE Options panel, as displayed by Rose's
config editor tool.

.. image:: images/moose_options.png

Dry-run Mode (option name: dry_run)
    If enabled, this option turns on the -n (``--dry-run``) argument for MOOSE
    commands encoded in task scripts. This will have the effect of reporting
    (in the log files) which files will be retrieved without the overhead of
    actually retrieving them. This can be useful for troubleshooting purposes.

Fill Gaps (option name: fill_gaps)
    If enabled, this option turns on the -i (``--fill-gaps``) argument for MOOSE
    commands encoded in task scripts. Typically it will be desirable to leave
    this option enabled so that you only retrieve those files that are not
    already on disk.

Force Overwrite Of Existing Files (option name: force)
    If enabled, this option turns on the -f (``--force``) argument for MOOSE
    commands encoded in task scripts. Mutually exclusive to the Fill Gaps option.

Ignore Missing Files (option name: get_if_available)
    If enabled, this option turns on the -g (``--get-if-available``) argument for
    MOOSE commands encoded in task scripts. Only applies to plain ``moo get`` commands.

Large Data Retrieval (option name: large_retrieval)
    If enabled, this option turns on the -b (``--large-retrieval``) argument for
    MOOSE commands encoded in task scripts.

Enable Compressed Data Transfers (option name: compressed_transfer)
    If enabled, this option turns on the -z (``--compressed-transfer``) argument for
    MOOSE commands encoded in task scripts.

Max Number of Data Transfer Threads (option name: max_transfer_threads)
    If enabled, this option turns on the -j (``--transfer-threads``) argument for
    MOOSE commands encoded in task scripts.

Data Cache Definitions (section name: data_caches)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The figure below illustrates the Data Cache Definitions panel, as displayed by Rose's
config editor tool (and accessed via the 'namelist' heading).

.. image:: images/data_caches.png

Cache Scheme (option name: scheme)
    This option permits selection of the Afterburner-supported data cache scheme
    that will determine how files retrieved from MASS will be laid down on disk
    for a particular data request.

Cache Identifier (option name: id)
    Specifies a unique, human-readable identifier for a data cache defintion,
    e.g. 'var_split'. This identifier is used in composite data requests (see below)
    to identify the on-disk cache scheme to use.

Cache Base Directory (option name: base_dir)
    Defines the absolute path of the cache's base directory. Files retrieved
    from MASS will be stored within subdirectories of the base directory.

Null Realization Directory (option name: null_realization_dir)
    This option may be used to specify the name of the subdirectory (e.g. 'r0')
    within an ensemble-based data cache below which to store -- usually in further
    subdirectories -- any files originating from *non-ensemble* climate experiments.
    If undefined (the default) then any attempt to store such files will give
    rise to a run-time error.

Data Requests (section name: requests)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The figure below illustrates the Data Requests panel, as displayed by Rose's
config editor tool (and accessed via the 'namelist' heading).

.. image:: images/data_requests.png

MASS Data Class (option name: data_class)
    Specifies the MASS data class for a data request: usually one of 'crum' or
    'ens'.

MASS Data Set(s) (option name: data_sets)
    Specifies a comma-separated list of the MASS data sets from which to retrieve
    data, e.g. ``anqjm,akmft`` for UMUI-type climate runs, or ``mi-ab123,mi-xy456``
    for Rose suites. The two forms can of course be mixed together if required.

MASS Data Collection(s) (option name: data_collections)
    Specifies a comma-separated list of the MASS data collections from which to
    retrieve data, e.g. ``apm.pp,apy.pp``.

Realization Identifier(s) (option name: realizations)
    For ensemble-based data requests, specifies a comma-separated list of the
    ensemble members from which to retrieve data, e.g. ``r1i1p1,r2i1p3,...``.

Data Variable(s) (option name: variables)
    Specifies a comma-separated list of STASH codes or (for netCDF data) variable
    names. Set to '*' or leave blank to retrieve all variables from the specified
    data collections.

    In the case of UM diagnostics it is possible to specify ``lbproc`` and/or
    ``lbtim`` constraints within square brackets immediately after the STASH code.
    For example, the variable definition ``m01s00i024[lbproc=128;lbtim=122]``
    would result in just the hourly-mean temperature diagnostic being retrieved.
    Note that multiple constraints must be separated by semicolon characters,
    as shown above.

    If it is desired to apply the same PP header constraints to *all* of the
    requested variables then it is quicker and easier to define the ``lbproc``
    and ``lbtim`` options at the request level, rather than the variable level.
    Refer to the `PP Header Words` section below for details of how to do this.

NetCDF Auxiliary Variable(s) (option name: aux_variables)
    In the case of netCDF-based requests, specifies a comma-separated list of
    any auxiliary variables to extract from netCDF files in addition to the
    primary data variable(s) defined by the previous option.

Calendar (option name: calendar)
    Specifies the calendar type associated with **all** of the files targetted
    by the data request. Recognised values are 'standard', 'gregorian',
    'proleptic_gregorian', '360_day' (the default), '365_day', and '366_day'.

Start Date (option name: start_date)
    If data for a specific time period is required then this option defines the
    inclusive start date. At present, an end date (see next entry) must also
    be specified. Otherwise, to retrieve the full time period available
    in MASS, both fields should be left blank. The specified date-time string
    can be in either MOOSE or ISO 8601 format, e.g. ``1970/01/01 12:00`` or
    ``1970-01-01T12:00:00``.

End Date (option name: end_date)
    If data for a specific time period is required then this option defines the
    exclusive end date. At present, a start date (see previous entry) must also
    be specified. Otherwise, to retrieve the full time period available
    in MASS, both fields should be left blank. The specified date-time string
    can be in either MOOSE or ISO 8601 format, e.g. ``1970/01/01 12:00`` or
    ``1970-01-01T12:00:00``.

NEMO Grid Type (option name: grid_type)
    This option may be used to select NEMO model data files matching a particular
    grid type, i.e. 'T', 'U', 'V', 'W', 'diaptr'. If undefined then data files for
    grid type 'T' are retrieved. (Note: currently, multiple data requests must
    be defined in order to retrieve data for two or more NEMO grid types. It is
    hoped that this constraint can be removed in a future version of the MDR app.)

Filename pattern for NEMO and CICE data files (option name: file_glob)
    Optionally specifies the glob pattern to use to match files generated by the
    NEMO or CICE models. This option is ignored if the ``start_date`` and ``end_date``
    options are defined.

Data Cache Identifier (option name: cache id)
    Specifies the unique identifier of the data cache definition associated with
    a particular data request. The value must be one of the identifiers defined
    under the `Data Cache Definitions` section above. A particular data cache
    identifier may, and often will, be referenced by several data requests.

PostProc Script Version Number (option name: postproc_vn)
    Specifies the version number of the post-processing script used by the model
    suite/run. The default is 1.0. Specify 2.0 to use CMIP6-compliant filenames.

PP Header Words (option names: lbproc, lbtim)
    In the case of UM data collections the ``lbproc`` and ``lbtim`` options may be
    used to further constrain which STASH diagnostics are retrieved. Note that if
    either option is defined then it applies to *all* of the variables covered by the
    parent data request. That, however, is unlikely to be a common scenario.

    Refer to the `Data Variables` section above for details of how to specify such
    constraints on individual variables/diagnostics. It is also possible to use both
    techniques, in which case variable-level constraints override request-level
    constraints.

Running the Application
-----------------------

The MDR application can be run either manually at the shell command line, or
automatically under the control of a Rose suite. Both methods are described in
general terms in the :doc:`/invoking` chapter. The guidance in that chapter is
applicable to the current context.

Manual Invocation
^^^^^^^^^^^^^^^^^

To run the app manually from the command line, type the following::

    % export AFTERBURNER_HOME_DIR=<path-to-afterburner-home-dir>
    % $AFTERBURNER_HOME_DIR/bin/abrun.sh MassDataRobot -c <config-file> [options]

An app config file, as described in the previous section, must be specified via
the ``-c`` (or ``--config-file``) option. Additional command-line options are
described below; often it is desirable to turn on the ``-v/--verbose`` option.

The ``export`` command above is not needed if the AFTERBURNER_HOME_DIR shell variable
is defined in one of your shell start-up scripts. Likewise, if the directory
$AFTERBURNER_HOME_DIR/bin is included in your command search path, then the
second command can be shortened to plain ``abrun.sh``.

If you have checked out (or exported) a working copy of the `Afterburner code base
<https://code.metoffice.gov.uk/trac/afterburner/browser/turbofan/trunk>`_ then you
can, if preferred, set the AFTERBURNER_HOME_DIR to point to the directory
containing that working copy.

Invoking the MDR app manually will of course only run it once. Sometimes, however,
you'll want to run it at regular intervals. This can be achieved by running the
aforementioned commands as a cron job scheduled to execute at the time of your
choosing (overnight, for example).

Alternatively, periodic execution of the MDR app can be controlled by the Rose/cylc
scheduler, as described in the next section.

Invocation from a Rose Suite
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Firstly, create a copy of the `u-an165`_ sample Rose suite (login required).

Next, modify the app config file for the MDR application (i.e. the file
``app/mass_data_robot/rose-app.conf``), and also the ``suite.rc`` file, to suit
your particular data retrieval requirements.

At this point you can either run the suite in stand-alone mode, or you can copy
the app directory over to an existing Rose suite and run (or restart) that suite.
In the latter case it will be necessary to modify the suite's dependency graph (in
the ``suite.rc`` file) so that the MDR app is invoked at the desired time points.
Please consult the relevant Rose and cylc documentation for further guidance on
how to do this.

The aforementioned suite is configured to parallelise data retrieval tasks using
Python's multiprocessing module. As an alternative, Rose suite `u-aq151`_ uses
the rose-bunch application to split up the data retrieval tasks into batches,
which are then executed under the control of the cylc scheduling system.

The batch size is controlled by the ``[bunch]pool-size`` app config property.
The other properties are configured in the same way as described under the
`Configuring the Application`_ part of this guide.

.. _mdr_command_opts:

Command-Line Options
^^^^^^^^^^^^^^^^^^^^

Command-line options can be viewed by invoking the app with the ``-h`` (or ``--help``)
option, as shown below::

    % abrun.sh -h
    Usage: abrun.sh <app_name> [options] [arguments]

    % abrun.sh MassDataRobot -h
    Usage: MassDataRobot [-h] [-V] [-D | -q | -v] [-n] -c CONFIG_FILE

    MASS Data Robot: retrieve model data from the MASS data archive.

    optional arguments:
      -h, --help            Show this help message and exit
      -V, --version         Show Afterburner version number and exit
      -D, --debug           Enable debug message mode
      -q, --quiet           Enable quiet message mode
      -v, --verbose         Enable verbose message mode
      -n, --dry-run         Dry-run only: echoes but does not run MOOSE commands
      --no-teardown         Skip final teardown operations (overrides config file setting)
      --pmode {pymp,none}
                            Specify parallel mode (overrides config file setting)
      -c CONFIG_FILE, --config-file CONFIG_FILE
                            Pathname of app configuration file

The ``--dry-run`` command-line option is distinct from the ``dry_run`` property
which can be specified in the app config file. The former results in all MOOSE
commands being echoed to the user's terminal without actually being invoked.
The latter turns on the ``--dry-run`` argument for each individual MOOSE command,
which, when subsequently invoked, has the effect of displaying the names of the
files that would be retrieved without actually fetching them.

The remaining options are fairly self-explanatory. Note, however, that the
-D, -q and -v options are mutually exclusive.

Example Data Requests
=====================

The example composite data requests shown below are intended to act as rough
templates for creating your own request definitions.

.. tip:: The line entry ``variables=*`` in several of the examples is included for the
   sake of completeness. Since this is the default setting for the ``variables``
   option, it can be omitted if the intention is to retrieve all variables from
   a data collection.

1. Retrieve all PP files containing UM annual mean diagnostics for 3 climate runs.
   Store the files in a StreamSplit-based data cache. ::

    [namelist:data_caches(1)]
    id=stream_split
    scheme=StreamSplit
    base_dir=$SCRATCH/caches/stream_split

    [namelist:requests(1)]
    data_class=crum
    data_sets=abcde,abpqr,abxyz
    data_collections=apy.pp
    variables=*
    cache_id=stream_split

2. As above, but only retrieve PP files covering the defined T1 time period. ::

    [namelist:data_caches(1)]
    id=stream_split
    scheme=StreamSplit
    base_dir=$SCRATCH/caches/stream_split

    [namelist:requests(2)]
    data_class=crum
    data_sets=abcde,abpqr,abxyz
    data_collections=apy.pp
    variables=*
    start_date=1988/12/01 00:00
    end_date=2008/12/01 00:00
    cache_id=stream_split

3. Retrieve all PP files containing UM annual and seasonal mean diagnostics for
   a single climate run. Store the files in a StreamSplit-based data cache. ::

    [namelist:data_caches(1)]
    id=stream_split
    scheme=StreamSplit
    base_dir=$SCRATCH/caches/stream_split

    [namelist:requests(3)]
    data_class=crum
    data_sets=abcde
    data_collections=apy.pp,aps.pp
    variables=*
    cache_id=stream_split

4. Retrieve two specific UM diagnostics from the monthly mean stream of a single
   Rose-style climate suite. Store the PP files in a VarSplit-based data cache. ::

    [namelist:data_caches(2)]
    id=var_split
    scheme=VarSplit
    base_dir=$SCRATCH/caches/var_split

    [namelist:requests(4)]
    data_class=crum
    data_sets=mi-ab123
    data_collections=apm.pp
    variables=m01s01207,m01s01i208
    cache_id=var_split

5. Retrieve all NEMO annual mean variables, for all available times, from 2
   climate runs. Store the netCDF files in a StreamSplit-based data cache. ::

    [namelist:data_caches(1)]
    id=stream_split
    scheme=StreamSplit
    base_dir=$SCRATCH/caches/stream_split

    [namelist:requests(5)]
    data_class=crum
    data_sets=abcde,mi-ab123
    data_collections=ony.nc.file
    variables=*
    cache_id=stream_split

6. Retrieve three named NEMO W-grid variables, for a 5-year time period, from the
   monthly mean stream of a single Rose-style climate suite. Store the netCDF
   files in a VarSplit-based data cache. ::

    [namelist:data_caches(2)]
    id=var_split
    scheme=VarSplit
    base_dir=$SCRATCH/caches/var_split

    [namelist:requests(6)]
    data_class=crum
    data_sets=mi-ab123
    data_collections=onm.nc.file
    variables=ws,wt,ww
    start_date=1980-12-01
    end_date=1985-12-01
    grid_type=W
    cache_id=var_split

7. Retrieve monthly-mean wind speed diagnostics for six ensemble runs from a
   single Rose-style climate suite. Store the retrieved PP files within an
   EnsembleVarSplit-based data cache. ::

    [namelist:data_caches(3)]
    id=ens_var_split
    scheme=EnsembleVarSplit
    base_dir=$SCRATCH/caches/ens_var_split

    [namelist:requests(7)]
    data_class=ens
    data_sets=mi-pq789
    data_collections=apm.pp
    realization_ids=r1i1p1,r1i1p2,r2i1p1,r2i1p2,r3i1p1,r3i1p2
    variables=m01s30i201,m01s30i202
    cache_id=ens_var_split

See Also
========

N/A

.. _u-an165: https://code.metoffice.gov.uk/trac/roses-u/browser/a/n/1/6/5/trunk

.. _u-aq151: https://code.metoffice.gov.uk/trac/roses-u/browser/a/q/1/5/1/trunk

.. _multiprocessing: https://docs.python.org/3.6/library/multiprocessing.html
