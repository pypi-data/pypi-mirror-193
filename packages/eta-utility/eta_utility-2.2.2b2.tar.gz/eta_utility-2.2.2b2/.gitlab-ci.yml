stages:
  - setup
  - check
  - test
  - deploy

.default_rules:
  rules:
    # Create pipelines for merge request events
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    # Create a pipeline for the default branch
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
    # Dont create a branch pipeline while there are open merge requests
    - if: '$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS'
      when: never

.on_version_tag_rule:
  rules:
    # Create a pipeline if a version tag was created
    - if: '$CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+([ab]\d+)?$/'

workflow:
  rules:
    # Create pipelines for merge request events
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
    # Create a pipeline for the default branch
    - if: '$CI_COMMIT_BRANCH == $CI_DEFAULT_BRANCH'
    # Create a pipeline if a version tag was created
    - if: '$CI_COMMIT_TAG =~ /^v\d+\.\d+\.\d+([ab]\d+)?$/'
    # Dont create a branch pipeline while there are open merge requests
    - if: '$CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS'
      when: never

include:
  - template: Security/Secret-Detection.gitlab-ci.yml
  - template: Security/License-Scanning.gitlab-ci.yml

# Setup pip cache so that it can be reused between jobs
variables:
  # Caching and cleanup setup
  PIP_CACHE_DIR: '$CI_PROJECT_DIR/.pip_cache'
  GIT_CLEAN_FLAGS: '-x -f -e .pip_cache/** -e venv/**'
  # Always use python version 3 for imported jobs
  ASDF_PYTHON_VERSION: 3
  # Deploy using upload token
  TWINE_PASSWORD: '${PYPI_UPLOAD_TOKEN}'
  TWINE_USERNAME: '__token__'

default:
  tags:
    - python
    - docker
  image: python:3.8
  before_script:
    - apt-get update
    - python -V  # Print out python version for debugging
    - python3 -m venv venv
    - source venv/bin/activate
    - pip install --upgrade pip
    - pip install --upgrade "setuptools<67"   # higher versions are incompatible with gym==0.21 (required by stable_baselines)
    - pip install .[develop]
  cache: &global_cache
    key: $CI_COMMIT_REF_SLUG
    paths:
      - .pip_cache
      - venv
    policy: pull

create_cache:
  stage: setup
  interruptible: true
  before_script:
    - apt-get update
  script:
    - rm -rf venv .venv .cache .pip_cache .pytest_cache .mypy_cache dist doc eta_utility.egg-info build public
    - rm -rf docs/_build docs/_stubs
    - ls -la
    - python -V
    - python3 -m venv venv --clear
    - source venv/bin/activate
    - pip install --upgrade pip
    - pip install --upgrade "setuptools<67"   # higher versions are incompatible with gym==0.21 (required by stable_baselines)
    - pip install .[develop]
    - pip install flake8-json
  cache:
    <<: *global_cache
    policy: push

isort:
  stage: check
  interruptible: true
  script:
    - pip install isort
    - isort -c -v .

black:
  stage: check
  interruptible: true
  script:
    - pip install black
    - black --check --config pyproject.toml eta_utility/ test/

flake8:
  stage: check
  interruptible: true
  script:
    - pip install flake8-json
    - flake8 --version
    - flake8 --config=setup.cfg --format=codeclimate --tee --output-file=flake8.json eta_utility examples test
  artifacts:
    reports:
      codequality: flake8.json

check-julia:
  stage: check
  image: julia:1.7.2
  interruptible: true
  before_script: []
  script:
    - julia -e '
      using Pkg;
      Pkg.add("JuliaFormatter");
      using JuliaFormatter;
      if !format("eta_utility/ju_extensions", verbose=true)
      @error "Some files have not been formatted !!!";
      exit(1);
      end'

license_scanning:
  stage: check
  interruptible: true
  needs: []
  before_script: []
  rules:
    - !reference [.default_rules, rules]

secret_detection:
  stage: check
  interruptible: true
  before_script: []
  rules:
    - !reference [.default_rules, rules]

test3.7:
  stage: test
  interruptible: true
  script:
    - pip install pytest pytest-cov
    - pytest --cov
  retry:
    max: 1
    when: script_failure

test3.9:
  stage: test
  image: python:3.9
  interruptible: true
  script:
    - pip install pytest pytest-cov
    - pytest --cov
  retry:
    max: 1
    when: script_failure

typecheck:
  stage: test
  interruptible: true
  script:
    - mypy -V
    - mypy --config-file pyproject.toml
    
# build the sources
build:
  stage: deploy
  script:
    - rm -rf dist
    - pip install build twine
    - python -m build --sdist --wheel
    - twine check dist/* && twine upload --verbose --repository pypi dist/*
  artifacts:
    name: "eta_utility-build-$CI_COMMIT_REF_NAME-$CI_JOB_STATUS"
    paths:
      - dist/
      - eta_utility.egg-info/
  rules:
    - !reference [.on_version_tag_rule, rules]

build_local:
  stage: deploy
  variables:
    TWINE_PASSWORD: '${CI_JOB_TOKEN}'
    TWINE_USERNAME: 'gitlab-ci-token'
  script:
    - rm -rf dist build
    - pip install build twine
    - python -m build --sdist --wheel
    - twine check dist/* && twine upload --verbose --repository-url https://$CI_SERVER_HOST/api/v4/projects/$CI_PROJECT_ID/packages/pypi dist/*
  rules:
    - !reference [.on_version_tag_rule, rules]

# Create readthedocs documentation
readthedocs:
  stage: deploy
  before_script: []
  needs: []
  script:
    - echo $CI_COMMIT_TAG
    - curl -X POST -d "branches=master" -d "token=$READTHEDOCS_TOKEN" https://readthedocs.org/api/v2/webhook/eta-utility/211185/
  rules:
    - !reference [.on_version_tag_rule, rules]

# Create sphinx html documentation
pages:
  stage: deploy
  script:
    - apt-get --yes install libgl1-mesa-glx
    - pip install sphinx sphinx-rtd-theme
    - rm -rf docs/_build docs/_stubs
    - cd docs
    - make html
    - rm -rf ../public/html/*
    - mv _build/html ../public
  artifacts:
    name: "eta_utility-docs-$CI_COMMIT_REF_NAME"
    paths:
      - public/
