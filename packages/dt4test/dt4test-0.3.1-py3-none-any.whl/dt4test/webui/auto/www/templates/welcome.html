<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8">
        <title>davinci</title>

        <link rel="stylesheet" href="{{ url_for('static', filename='lib/easyui/themes/bootstrap/easyui.css') }}">
        <link rel="stylesheet" href="{{ url_for('static', filename='lib/easyui/themes/icon.css') }}">

        <link rel="stylesheet" href="{{ url_for('static', filename='css/auto.css') }}">

        <link rel="icon" type="image/x-icon" href="{{ url_for('static', filename='favicon.ico') }}" />

    </head>
    <body>
    <h2>测试用例设计系统</h2>
    <p>针对各种场景，采用各种模型进行测试用例设计，从而自动生成文本测试用例，甚至是半自动对测试用例。</p>
    <div style="margin:20px 0 10px 0;"></div>
    <div class="easyui-accordion" style="height:550px;">
        <div title="系统测试" data-options="iconCls:'icon-logo_16'" style="overflow:auto;padding:10px;">
            <h3 style="color:#0099FF;">测试执行只是系统测试工作的核心部分，还有其它，必须有</h3>
            <li>用例是测试执行的核心，时刻在左边，手工和自动化用例统一管理，它们只是执行上的区别</li>
            <li>测试环境的信息应该是自动获取的，如果你将测试工具箱放在了测试环境上</li>
            <li>手动的任务、定时执行的任务都应该被合理管理</li>
            <li>监控告警应该紧随任务出生、入死，不要永驻，不要僵尸</li>
            <li>异常需要考虑、性能不能降低、最好得到最优配置组合</li>
            <li>分析测试的过程、分析项目的运作，每次都有收获，每次都有改进</li>
            <p>君欲善其事，必先利其器，出门看病要带工具箱，不能只有针头和药水</p>
        </div>
        <div title="测试环境" data-options="iconCls:'icon-test_env'" style="padding:10px;">
            <h3 style="color:#0099FF;">测试执行的默认设定</h3>
            <li>当前测试的是什么系统，版本号是多少</li>
            <li>在什么机器上测试，机器、系统的配置是什么样的</li>
            <li>如果是分布式环境，拓扑信息如何、组件状态是否健康.</li>
            <p>环境对测试的影响就像环境对人的影响一样大，只是人的环境难以自动获取</p>
        </div>
        <div title="任务管理" data-options="iconCls:'icon-task_mng'" style="padding:10px;">
            <h3 style="color:#0099FF;">一步一个脚印，每一步都掷地有声</h3>
            <li>记录每一次执行的过程，可以重复执行，执行成功的，执行失败的，设置成定时任务</li>
            <li>有些任务是耗时的，不要等待，只需稍后来这里看一下执行结果，日志和报告</li>
            <p>一键完成所有测试，通常是遥远的理想</p>
        </div>
        <div title="调度管理" data-options="iconCls:'icon-schedule_mng'" style="padding:10px;">
            <h3 style="color:#0099FF;">每天和机器打交道，尽可能让机器帮我们做更多的事</h3>
            <li>我们设置了哪些定时执行的任务、重复执行的任务</li>
            <li>这些任务具体什么时间运行，最近一次是什么时间运行的，下一次什么时间运行</li>
            <li>运行的结果如何，日志和报告查看</li>
            <li>是否需要暂停或删除</li>
            <p>自动化测试是测试过程中最美的体验，使用工具使人类进步</p>
        </div>
        <div title="监控告警" data-options="iconCls:'icon-monitor'" style="padding:10px;">
            <h3 style="color:#0099FF;">有些任务的运行需要关注机器或系统的某些参数指标</h3>
            <li>定义这些指标（如果没有），赋予ID，在测试计划中引入这些ID，监控它们</li>
            <li>不用担心指标太多，测试计划的 post-step 会清理掉它们</li>
            <li>多个测试任务可以共用同一个监控ID，同一个测试系统，指标都是一样的</li>
            <li>新增告警，在所有的监控中选择你的指标，给出阈值，不要做甩手掌柜，意外本非意外</li>
            <p>多一双眼睛，多一种真相</p>
        </div>
        <div title="故障注入" data-options="iconCls:'icon-inject'" style="padding:10px;">
            <h3 style="color:#0099FF;">异常并非偶然，我们可以模拟、构造它们</h3>
            <li>定义异常脚本（如果没有），赋予ID，在测试计划中引入这些ID，可以在监控中看它们是否生效</li>
            <li>不用担心异常影响后续测试，测试计划的 post-step 会恢复它们</li>
            <li>多个测试任务不可以共用同一个异常，不建议异常注入下同时执行有干扰的测试任务</li>
            <p>万物无好坏，事事无异常</p>
        </div>
        <div title="性能基准" data-options="iconCls:'icon-performance'" style="padding:10px;">
            <h3 style="color:#0099FF;">每个版本都有可能引起性能的波动，有必要考察下性能是否波动太大</h3>
            <li>可以自定义业务的基准，也可以引入业界通用的基准测试</li>
            <li>通过系统的"上传测试数据"的功能，会保存每次的基准测试信息，作为对比依据</li>
            <li>多个基准，用ID分辨它们</li>
            <p>版本有基准，做人有底线</p>
        </div>
        <div title="调优大盘" data-options="iconCls:'icon-turning'" style="padding:10px;">
            <h3 style="color:#0099FF;">想找到系统在特定测试场景下的最优表现，需要不断调优</h3>
            <li>设定输入参数的变化范围，变更步长，多个参数的变更方式</li>
            <li>告诉系统不要关注的监控指标，告警阈值</li>
            <li>让系统自动的跑多次，并记录下指标的变化情况，甚至给出参数变化与指标的拟合曲线，得出系统最优的参考配置</li>
            <li>对于一个系统的调优，也应该是一个经验逐步积累的过程，最好能记录下过程数据</li>
            <p>一切皆有可能</p>
        </div>
        <div title="测试分析" data-options="iconCls:'icon-analyse'" style="padding:10px;">
            <h3 style="color:#0099FF;">测试不仅要完成任务，还要评估结果</h3>
            <li>用例，执行、缺陷、回归，所有的数据都值得被收集记录</li>
            <li>数据不是结论、结果；其背后反应出的信息才是真正的价值所在</li>
            <li>用例的变更情况，反应出前期投入、测试设计的质量</li>
            <li>测试执行，反应出测试过程的规范程度，测试投入的成本</li>
            <li>缺陷的多维度分析，反馈出整体质量，模块质量，潜在风险等</li>
            <li>有的结论指导后续版本运作改进，有的结论指导版本后续运营的关注重点</li>
            <p>透过现象，发现本质，踏踏实实</p>
        </div>
        <div title="测试报告" data-options="iconCls:'icon-report'" style="padding:10px;">
            <h3 style="color:#0099FF;">测试的结论与分析总结</h3>
            <li>版本的最终测试结论，是否可以发布</li>
            <li>测试的内容及结果</li>
            <li>测试的分析与结论</li>
            <li>上线、运营的指导与建议</li>
            <li>遗留的问题与后续的运作改进</li>
            <p>有始有终</p>
        </div>
        <div title="辅助工具" data-options="iconCls:'icon-tools'" style="padding:10px;">
            <h3 style="color:#0099FF;">工具要成套，扩展很必要</h3>
            <li>测试过程中可能用到各种外部工具，放在这个盒子里，减少各种查找、输入的时间</li>
            <li>测试数据的构造工具</li>
            <li>编解码的对比工具</li>
            <li>复杂结构的格式化工具</li>
            <li>... ...</li>
            <p>它山之石，可以攻玉</p>
        </div>
    </div>
        <div title="Wellcome" style="padding:10px">
            <h4>简单上手指南</h4>
            <ul>
                <li>安装：virtualenv新建 pyenv，版本3.7.5以上，pip install -q requiements.txt</li>
                <li>启动：./start_work.sh</li>
                <li>template目录下是中文，可以用 _en 目录替换出英文</li>
                <li><h5>使用</h5></li>
                <li>主要操作，请查看右键菜单：项目右键、目录右键、文件右键</li>
                <li>新建项目：直接新建，git拉取</li>
                <li>新建目录：直接新建，git拉取，excel导入，zip导入</li>
                <li>执行用例：右键按目录，单个文件执行，标记手工用例（执行日志见"调度管理"）</li>
                <li>用例报告，执行报告，用例列表：右键，按目录统计</li>
            </ul>
            <ul>
                <li>基于Git社区开源的AutoLink框架，实现如下扩展.</li>
                <li>打破原有user-project-suite-testcase固定的四层结构，实现user-porject下多层嵌套，从而支持lib、resource等更灵活等目录布局</li>
                <li>扩展原有robot、resource文件的支持，增加python文件的高亮支持，python的调试执行，从而实现对Robot动态库的编写与调试</li>
                <li>通过改造开源工具bzt，实现基于yaml配置文件的测试方案的执行，同时支持其他执行引擎如：pytest，jmeter等等。</li>
                <li>修复原有系统editor自动完成经常误操作的bug，并实现高亮、自动完成、关键字的关联展示，摒弃原有的全部显示，并支持递归探索，提高命中率、选择效率</li>
                <li>增加"调试执行"按钮，直接现实结果，实现快速用例调试；新建文件时同时打开editor，提升易用性；</li>
                <li>升级原有RobotFramwork版本，从两年前的3.0.3到现在的3.1.2</li>
                <li>将关键字按长度倒序排列，从而修复了高亮显示中，"Log To Consle" 只高亮 "Log" 的问题。</li>
                <li>实现了：合作项目功能（目前只是个人项目）</li>
                <li>实现了：用例excel导入和手工用例标记，自动化用例自动标记、相关测试执行统计、报告功能</li>
                <li>实现了：测试用例导出（自动化、手工），测试执行过程导出，对接外部相关测试管理系统，告别离岸的测试缺少统计</li>
                <li>--不做测试管理平台，而是测试执行工具平台，不是拉你入驻，如果对你有用，请在你的测试环境上安装使用.</li>
                <li>--不仅仅是执行工具，希望成为测试执行工具箱，成为你战场上的有力辅助.</li>
                <li>--让测试人员专注于测试设计和测试执行，远离统计、汇报.</li>
            </ul>
            <p style="font-size:16px">UniRobot 开发指南</p>
            <ul>
                <li>已知bug：本系统使用Python3.7+ ,RobotFramework的api如果遇到python2实现的lib库，可能吐出大量异常，阻塞后台</li>
                <li>project-tree 中Case的内容分析与展示，project.py:get_case_data()</li>
                <li>editor 展示新类型的文件autojs:onDblClick(),do_init(),dashboard.html:create_file_ff,edit_file_ff,blueprint.py:editor/key,case.py:create,edit</li>
                <li>任务执行的种类和方式task.py, utils:run.py</li>
                <li>展开project同时，创建了project的语法高亮和自动完成js</li>
                <li>打开每一个editor的tab页面，都会先替换语法高亮和自动完成js，再加载页面</li>
                <li>右侧的keywords ，会关联打开文件引用的resource下的KeyWords，且递归探索展示</li>
                <li>icon:utils里的resource：ICONS，还有js/auto.css链接到具体png</li>
            </ul>
            <p>如果你什么想法，欢迎和 charisma 交流</p>
            <p>项目源码:
                        <a target="_blank" href="https://github.com/mawentao119/uniRobot.git">github</a>
            </p>
        </div>

        <script src="{{ url_for('static', filename='lib/easyui/jquery.min.js') }}"></script>
        <script src="{{ url_for('static', filename='lib/easyui/jquery.easyui.min.js') }}"></script>
        <!-- 自定义js库 -->
    </body>
</html>